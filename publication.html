<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">


<link rel="icon" href="./img/nft_1~2.png" sizes="50x50">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

    <head>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

        <title>Peng Xia&#39;s homepage</title>

        

        <!-- CSS -->

        <link href="css" rel="stylesheet" type="text/css">

        <link rel="stylesheet" href="style.css" type="text/css" media="screen">

        <!-- ENDS CSS -->

        <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>

        

        <!-- ENDS JS -->  

    </head> 

    <body>

        <!-- MAIN -->

        <div id="">

            <div id="match-nav-wrapper">

               <div id="match-nav-bar">

                     <table>

                        <thead>

                            <tr valign="bottom">

                                <th width="" style="font-size: 25px;  color: #dddddd">Peng Xia</th>

                               <th width=40% ></th>

                                <th width=""><a href="index.html">HOME |</a> </th>

                                <th width=""><a href="publication.html"> RESEARCH |</a></th>

                                <th width=""><a href="cv.html">CV</a></th>

                            </tr>

                        </thead>

                    </table>

                </div>

            </div>

            <!-- HEADER -->





            <div id="main-wrapper">



                <div id="portfolio-info">

                <h1>üìùPublications</h1>

                    <table id="portfolio-projects">
                        <p>* indicates equal contribution; <sup>‚Ä†</sup> indicates corresponding authorship.</p>

                        <tbody>
                            
                            
                          <!-- <tr style="border-width: 1px">
                            <td><img src="./img/fig5.png" style="margin-bottom: 12px"></td>
                            <td bgcolor="#e4e4e4">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                     <b>GraphCLIP: Exploring Vision-Language Models with Graph Representation for Hierarchical Understanding.</b><br>
                                     <b>P. Xia</b>, X. Yu, M. Hu, L. Ju<sup>‚Ä†</sup>, Z. Wang, P. Duan, Z. Ge<sup>‚Ä†</sup>.<br>
                                      arXiv, 2023. <br>
                                      <a href="">Paper</a> &nbsp;¬∑&nbsp;
                                    <a href="">Code</a>    
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr>  -->
                            
                            
                            
                         
                         <tr style="border-width: 1px">
                            <td><img src="./img/fig3.png" style="margin-bottom: 12px"></td>
                            <td style="">
                                <table style="width: 100%;">
                                    <tbody><tr>
                                            <td style="width: 100%; text-align: left;">
                                            <p>
                                    <b>LMPT: Prompt Tuning with Class-Specific Embedding Loss for Long-Tailed Multi-Label Visual Recognition. </b><br>
                                    <b>P. Xia</b>, D. Xu, L. Ju<sup>‚Ä†</sup>, M. Hu, J. Chen, Z. Ge.<br>
                                    arXiv, 2023. <br>                           
                                    <a href="https://arxiv.org/pdf/2305.04536">Paper</a>&nbsp;¬∑&nbsp;
                                    <a href="https://github.com/richard-peng-xia/LMPT">Code</a> <a href="https://github.com/richard-peng-xia/LMPT"><img src="https://img.shields.io/github/stars/richard-peng-xia/LMPT?style=social&label=Code+Stars"></img></a>       
                                            </p>
                                            </td>
                                <td style="width: 10px;">
                                </td>
                                </tr></tbody></table>           
                            </td>
                        </tr>  
                            
                            
                            
                        <tr style="border-width: 1px">
                            <td><img src="./img/fig4.png" style="margin-bottom: 12px"></td>
                            <td bgcolor="#e4e4e4">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                     <b> NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding.</b><br>
                                     M. Hu*, L. Wang*, S. Yan*, D. Ma*, Q. Ren, <b>P. Xia</b>, W. Feng, P. Duan, L. Ju, Z. Ge<sup>‚Ä†</sup>.<br>
                                     NeurIPS Datasets and Benchmarks Track, 2023. <br>
                                     <a href="https://arxiv.org/pdf/2310.13347">Paper</a>&nbsp;¬∑&nbsp;
                                    <a href="https://github.com/minghu0830/NurViD-benchmark">Code</a> <a href="https://github.com/minghu0830/NurViD-benchmark"><img src="https://img.shields.io/github/stars/minghu0830/NurViD-benchmark?style=social&label=Code+Stars"></img></a>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 
                            
                            
                            
                            
                       <tr style="border-width: 1px">
                            <td><img src="./img/fig2.png" style="margin-bottom: 12px"></td>
                            <td style="">
                                <table style="width: 100%;">
                                    <tbody><tr>
                                            <td style="width: 100%; text-align: left;">
                                            <p>
                                    <b>Detecting Cognitive Impairment in Atrial Fibrillation Patients: A Deep Learning Model Based on Fundus Photographs. </b><br>
                                    Z. Wang*, C. Jiang*, <b>P. Xia*</b>, J. Ma, Y. Bai, Y. Lai, X. Peng, S. Li, T. Ma, L. Ju, L. He, X. Guo, S. Li, W. Wang, C. Jiang, N. Liu, R. Tang, D. Long, Y. Chen, C. Sang<sup>‚Ä†</sup>, X. Du, Z. Ge, J. Dong, W. Wei<sup>‚Ä†</sup>, C. Ma<sup>‚Ä†</sup>.<br>
                                    <!-- 2023. <br>                            -->
                                    <!-- <a href="">Paper</a>&nbsp;¬∑&nbsp;
                                    <a href="">Project Page</a>             -->
                                            </p>
                                            </td>
                                <td style="width: 10px;">
                                </td>
                                </tr></tbody></table>           
                            </td>
                        </tr>  
                            
                            
                            
                        <tr style="border-width: 1px">
                            <td><img src="./img/fig1.png" style="margin-bottom: 12px"></td>
                            <td bgcolor="#e4e4e4">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                     <b> Chinese Grammatical Error Correction Based on Knowledge Distillation.</b><br>
                                     <b>P. Xia</b>, Y. Zhou, Z. Zhang, Z. Tang, J. Li<sup>‚Ä†</sup>.<br>
                                      arXiv, 2022. <br>
                                      <a href="https://arxiv.org/pdf/2208.00351">Paper</a> &nbsp;¬∑&nbsp;
                                      <a href="https://github.com/richard-peng-xia/KD-CGEC">Code</a> <a href="https://github.com/richard-peng-xia/KD-CGEC"><img src="https://img.shields.io/github/stars/richard-peng-xia/KD-CGEC?style=social&label=Code+Stars"></img></a>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <br> <br>
                                <h1 style="font-weight: bold;">üé®Patents</h1>
                                <ul>
                                    <li><a href="https://www.patentstar.com.cn/Search/Detail?ANE=8ECA6DDA8CEA9FCB2BAA5BDA9GGFCIEA9HDG3BCADIDA9IFH">Model training method, device, electronic device and storage medium.</a><br>
                                    <b>P. Xia</b>, T. Ma, ..., Z. Ge & D. Zhang.<br>
                                    CN Patent. CN202311275093.4, 2023.<br> 
                                    </li>
                                </ul>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr>

                        <tr style="border-width: 1px">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <ul>
                                    <li>
                                    <a href="https://www.patentstar.com.cn/Search/Detail?ANE=7EBA9FGC6CCA7CCA9FEB9GIG9DGCAEGABHGA9GHE9DCF5AFA">Model training method, device, electronic device and storage medium.</a><br>
                                    <b>P. Xia</b>, T. Ma, ..., Z. Ge & D. Zhang.<br>
                                    CN Patent. CN202311275090.0, 2023.<br>
                                    </li>
                                </ul>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                <a href="https://www.patentstar.com.cn/Search/Detail?ANE=AIHA7BGA9GFE9EHF9HBA3DAACHHAEGIA7DBAAAIA9FCD9DFC">Method, device, equipment and medium for anxiety and depression detection.</a><br>
                                <b>P. Xia</b>, T. Ma, B. Wang, Z. Ge & D. Zhang.<br>
                                CN Patent. CN202310573953.6, 2023.<br>
                                </li>
                            </ul>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                <a href="https://www.patentstar.com.cn/Search/Detail?ANE=9DEA3ADA9HBB9FIH9IHH6CEA8BGA9FDBGGIACEHA9GDE9HEE">Method, device, equipment and medium for determining mental resilience based on fundus images.</a><br>
                                <b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
                                CN Patent. CN202310129842.6, 2023.<br>
                                </li>
                            </ul>
                            </p>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                <a href="https://www.patentstar.com.cn/Search/Detail?ANE=5DAA4BDA9DIE9IDE7BFA7GAA9FCE9EDB5BBA8BBA9HBBADGA">Model training method, fundus image prediction method and device.</a><br>
                                <b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
                                CN Patent. ZL202211633628.6, 2022.<br>
                                </li>
                            </ul>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                <a href="https://www.patentstar.com.cn/Search/Detail?ANE=9EFC3CBA7DCA9CGB9EHD6BEABEIA6FAA6EBA5EBA7AFA8DDA">Device for predicting cognitive impairment and computer readable storage medium.</a><br>
                                <b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
                                CN Patent. ZL202211611022.2, 2022.<br>
                                </li>
                            </ul>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                Article quality discrimination software based on multi-model transfer pre-training.<br>
                                J. Li, <b>P. Xia</b>, K. Zeng, et al.<br>
                                CN Software Copyright. 2022SR0228307.<br>
                                </li>
                            </ul>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                    <tr style="border-width: 1px">
                            <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                            <ul>
                                <li>
                                Lane detection system based on cascaded convolutional neural network.<br>
                                J. Li, K. Zeng, <b>P. Xia</b>.<br>
                                CN Software Copyright. 2022SR0248890.<br>
                                </li>
                            </ul>
                            </td><td style="width: 10px;">
                            </td>
                            </tr>
                            </tbody></table>           
                        </td>
                    </tr>

                

            </div>

            </div>

        </div>


        <!-- ENDS MAIN -->  

  

 

    

</div></div></body></html>
