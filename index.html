<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<link rel="icon" href="./img/nft_1~2.png" sizes="50x50">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Peng Xia, Xia Peng, AI, CS, Soochow University, Monash University, Airdoc"> 
<meta name="description" content="Peng Xia&#39;s homepage">
<meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Peng Xia&#39;s Homepage</title>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>

</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/richard-peng-xia" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<style type="text/css">
</style>
<table>
	<tbody>
		<tr>
			<td width="650">
				<div id="toptitle">
 					<h1>Peng(Richard) Xia &nbsp; <b style="font-family:STKaiti">Â§èÈπè</b></h1>
					<h1></h1>
				</div>

				<h3>Senior Undergraduate Student</h3> 
				
				<p>
					<a href="http://scst.suda.edu.cn">School of Computer Science and Technology</a>,  <br>
					<a href="https://eng.suda.edu.cn/">Soochow University</a>. <br>
					<br>
					Address: 801 Building B3, No. 180 Yizhou Road, Xuhui District, Shanghai, 200233 China <br>
					Email: richard.peng.xia [at] gmail.com; 1909401089 [at] stu.suda.edu.cn
				</p>
				<p> 
					<a href="https://scholar.google.com/citations?user=8OVOf1EAAAAJ"><img src="./img/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/richard-peng-xia"><img src="./img/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.cn/incareer/in/peng-xia-a98783239"><img src="./img/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.researchgate.net/profile/Peng-Xia-26"><img src="./img/rg.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://orcid.org/0000-0003-2676-9128"><img src="./img/orcid.jpeg" height="30px" style="margin-bottom:-3px"></a>
					
				</p>
			</td>
			<td>
				<img src="./img/xp.jpg" border="0" width="130"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2 id="biography">üìúBiography</h2>
<p>
	I am a senior undergraduate in the <a href="http://scst.suda.edu.cn/">School of Computer Science and Technology</a>, <a href="https://eng.suda.edu.cn/">Soochow University</a>. I am also a research assistant at <a href="https://www.monash.edu/">Monash University</a>. 
	In 2023 fall, I will join the <a href="https://www.monash.edu/mmai-group">Monash Medical AI Group (MMAI)</a> as a Ph.D. student at <a href="https://www.monash.edu/">Monash University</a>, advised by A/Prof. <a href="https://scholar.google.com.au/citations?user=Q0gUrcIAAAAJ&hl=en">Zongyuan Ge</a>, Dr. <a href="https://research.monash.edu/en/persons/ben-duan">Peibo Duan</a> and Dr. <a href="https://scholar.google.com/citations?user=bbyetzcAAAAJ&hl=zh-CN&oi=ao">Deval Mehta</a>. 
</p>
<!--a research intern in <a href="https://www.airdoc.com/english/index.html">Airdoc</a>, Shanghai I am fortunate to have research attachments and internships at <a href="http://iai.suda.edu.cn/">IAI@SUDA</a> and <a href="http://scst.suda.edu.cn/28250/list.htm">NLPRC@SUDA</a>, advised by Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=CncXH-YAAAAJ">Min Zhang</a>, Dr. <a href="https://lijuntaopku.github.io/">Juntao Li</a> and Dr. <a href="https://dblp.uni-trier.de/pid/08/500.html">Junhui Li</a>.   -->
<p> My research lies at the intersection of vision and language, mainly focusing on medical field. I am always open to collaboration. Feel free to drop me an e-mail. :-) </p>

<h2 id="news">‚ú®News</h2>
<!-- <div style="height: 280px; overflow: auto;"> -->
<div style="overflow: scroll;">
<ul>
	<li>
		[07/2023] I join <a href="https://www.monash.edu/mmai-group">Monash Medical AI Group (MMAI)</a> to pursue a Ph.D. degree at Monash University.
	</li>
	<li>
		[08/2022] Share paper list about <a href="https://github.com/richard-peng-xia/awesome-multimodal-in-medical-imaging">multi-modal learning in medical imaging</a>. <a href="https://github.com/richard-peng-xia/awesome-multimodal-in-medical-imaging"><img src="https://img.shields.io/github/stars/richard-peng-xia/awesome-multimodal-in-medical-imaging?style=social&label=Code+Stars"></img></a>
	</li>
	<li>
		[07/2022] I start working at <a href="https://www.airdoc.com/english/index.html">Airdoc</a> as a research intern in Shanghai.
	</li>
	<li>
		[06/2022] I won third place award in <a href="http://fudan-disc.com/sharedtask/social22/">Shanghai-HK Interdisciplinary Shared Tasks(2022)</a> task 1 "Trigger Identification". <a href="./assets/shanghai_hk_shared_task_report.pdf">[report]</a>  <a href="./assets/shanghai_hk_shared_task_slide.pdf">[slides]</a> <a href="https://github.com/richard-peng-xia/Trigger-Identification">[code]</a>
	</li>
</ul>
</div>
	

<h2 id="publications">üìùSelected Publications</h2>
<!-- <ul>
	<sup>*</sup> indicates equal contribution; <sup>‚Ä†</sup> indicates corresponding authorship.
</ul>	
	<h3>Preprints</h3>
<ul>
	<li>
		<tr><td> <b>P. Xia</b>, D. Xu, L. Ju, M. Hu, J. Chen and Z. Ge<sup>‚Ä†</sup>. LMPT: Prompt Tuning with Class-Specific Embedding Loss for Long-Tailed Multi-Label Visual Recognition.  </td></tr>
	</li>
	<li>
		<tr><td> Z. Wang*, C. Jiang*, <b>P. Xia*</b>, J. Ma, Y. Bai, Y. Lai, X. Peng, S. Li, T. Ma, L. Ju, L. He, X. Guo, S. Li, W. Wang, C. Jiang, N. Liu, R. Tang, D. Long, Y. Chen, C. Sang<sup>‚Ä†</sup>, X. Du, Z. Ge and C. Ma<sup>‚Ä†</sup>. Detection of cognitive dysfunction in patients with atrial fibrillation: a deep learning model based on fundus images. Submitted to Lancet Digital Health.  </td></tr>
	</li>
	<li>
		<tr><td> <b>P. Xia</b>, Y. Zhou, Z. Zhang, Z. Tang. and J. Li<sup>‚Ä†</sup>. Chinese grammatical error correction based on knowledge distillation[J]. arXiv preprint arXiv:2208.00351, 2022. <a href="https://arxiv.org/abs/2208.00351">[abs]</a> <a href="https://arxiv.org/pdf/2208.00351">[pdf]</a> <a href="https://github.com/richard-peng-xia/KD-CGEC">[code]</a> </td></tr>
	</li>
</ul>	 -->
	
	
<table id="tbPublications" width="100%">
	<tbody>
	<ul>
		* indicates equal contribution; <sup>‚Ä†</sup> indicates corresponding authorship.
	</ul>

	<tr>
		<td width="270">
		<img src="./img/fig3.png" width="250px" style="box-shadow: 4px 4px 8px #888" class="center">
		</td>		
		<td> LMPT: Prompt Tuning with Class-Specific Embedding Loss for Long-Tailed Multi-Label Visual Recognition. <br>
			<b>P. Xia</b>, D. Xu, L. Ju<sup>‚Ä†</sup>, M. Hu, J. Chen, Z. Ge. <br>
		<!-- <em>Submitted to International Conference on Computer Vision(<i><b>ICCV</b></i>)</em>, 2023. -->
		<em>Under Review</em>.
		<p>[<a href="https://arxiv.org/pdf/2305.04536" target="_blank">paper</a>][<a href="https://github.com/richard-peng-xia/LMPT" target="_blank">code</a>]<a href="https://github.com/richard-peng-xia/LMPT"><img src="https://img.shields.io/github/stars/richard-peng-xia/LMPT?style=social&label=Code+Stars"></img></a></p>
		<a href="https://paperswithcode.com/sota/long-tail-learning-on-coco-mlt?p=lmpt-prompt-tuning-with-class-specific"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/lmpt-prompt-tuning-with-class-specific/long-tail-learning-on-coco-mlt"></img></a>
		<a href="https://paperswithcode.com/sota/long-tail-learning-on-voc-mlt?p=lmpt-prompt-tuning-with-class-specific"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/lmpt-prompt-tuning-with-class-specific/long-tail-learning-on-voc-mlt"></img></a>
	</td>
	</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
		
	<tr>
		<td width="270">
		<img src="./img/fig2.png" width="250px" style="box-shadow: 4px 4px 8px #888" class="center">
		</td>		
		<td> Detection of cognitive dysfunction in patients with atrial fibrillation: a deep learning model based on fundus photographs. <br>
			Z. Wang*, C. Jiang*, <b>P. Xia*</b>, J. Ma, Y. Bai, Y. Lai, X. Peng, S. Li, T. Ma, L. Ju, L. He, X. Guo, S. Li, W. Wang, C. Jiang, N. Liu, R. Tang, D. Long, Y. Chen, C. Sang<sup>‚Ä†</sup>, X. Du, Z. Ge, J. Dong, W. Wei<sup>‚Ä†</sup>, C. Ma<sup>‚Ä†</sup>.  <br>
		<em>Submitted to Frontiers of Medicine</em>.
		<p>[<a href="" target="_blank">paper</a>]</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
		
	<tr>
		<td width="270">
		<img src="./img/fig1.png" width="250px" style="box-shadow: 4px 4px 8px #888" class="center">
		</td>		
		<td> Chinese grammatical error correction based on knowledge distillation. <br>
			<b>P. Xia</b>, Y. Zhou, Z. Zhang, Z. Tang. and J. Li<sup>‚Ä†</sup>. <br>
		<em>Project Report</em>, 2022. 
		<p>[<a href="https://arxiv.org/pdf/2208.00351" target="_blank">paper</a>][<a href="https://github.com/richard-peng-xia/KD-CGEC" target="_blank">code</a>]<a href="https://github.com/richard-peng-xia/KD-CGEC"><img src="https://img.shields.io/github/stars/richard-peng-xia/KD-CGEC?style=social&label=Code+Stars"></img></a></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
	    <tr>&nbsp</tr>
	    <tr>&nbsp</tr>
</tbody></table>

	
<h2 id="patents">üé®Patents</h2>
<ul>
	<li>
		A fundus image prediction method for mental elasticity based on deep learning.<br>
		<b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
		CN Patent. Under Review.<br>
	</li>

	<li>
		<a href="https://www.patentstar.com.cn/Search/Detail?ANE=5DAA4BDA9DIE9IDE7BFA7GAA9FCE9EDB5BBA8BBA9HBBADGA">Model training method, fundus image prediction method and device.</a><br>
		<b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
		CN Patent. CN202211633628.6, 2022.<br>
	</li>
	
	<li>
		<a href="https://www.patentstar.com.cn/Search/Detail?ANE=9EFC3CBA7DCA9CGB9EHD6BEABEIA6FAA6EBA5EBA7AFA8DDA">Device for predicting cognitive impairment and computer readable storage medium.</a><br>
		<b>P. Xia</b>, L. Ju,..., Z. Ge & D. Zhang.<br>
		CN Patent. ZL202211611022.2, 2022.<br>
	</li>
	
	<li>
		Article quality discrimination software based on multi-model transfer pre-training.<br>
		J. Li, <b>P. Xia</b>, K. Zeng, et al.<br>
		CN Software Copyright. 2022SR0228307.<br>
	</li>
	
	<li>
		Lane detection system based on cascaded convolutional neural network.<br>
		J. Li, K. Zeng, <b>P. Xia</b>.<br>
		CN Software Copyright. 2022SR0248890.<br>
	</li>
</ul>
	
	
<h2 id="experiences">üëîExperiences</h2>
<ul>
<li>	
	<tr><td> Research Assistant, Monash Medical AI (MMAI), Monash University (01/2023-06/2023). <br>
	Advisor: A/Prof. <a href="https://scholar.google.com.au/citations?user=Q0gUrcIAAAAJ&hl=en">Zongyuan Ge</a>. <br>
	</td></tr>
</li>
<li>	
	<tr><td> Research Intern, Airdoc (07/2022-01/2023). <br>
	Advisor: Ph.D. candidate <a href="https://scholar.google.com.au/citations?user=Q6XB27gAAAAJ&hl=en">Lie Ju</a> and A/Prof. <a href="https://scholar.google.com.au/citations?user=Q0gUrcIAAAAJ&hl=en">Zongyuan Ge</a>. <br>
	</td></tr>
</li>
<li>	
	<tr><td> UASR Summer Courses, Duke-NUS Medical School, National University of Singapore (06/2022-07/2022). <br> 
	</td></tr>
</li>
<li>	
	<tr><td> Research Intern, Institute of Artificial Intelligence, Soochow University (12/2021-04/2022). <br> 
	Advisor: Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=CncXH-YAAAAJ">Min Zhang</a> and Dr. <a href="https://lijuntaopku.github.io/">Juntao Li</a>. <br>
	</td></tr>
</li>
<li>	
	<tr><td> Research Intern, Natural Language Processing Research Centre, Soochow University (10/2021-11/2021). <br> 
	Advisor: Dr. <a href="https://dblp.uni-trier.de/pid/08/500.html">Junhui Li</a>. <br>	
	</td></tr>
</li>
<li>	
	<tr><td> Intern, China Construction Bank (07/2021-08/2021). <br>
	</td></tr>
</li>
<li>
	<tr><td> Vice President, Science and Technology Association, Soochow University (10/2020-07/2021). <br>
	</td></tr>
</li>	
</ul>	
	


<h2 id="awards">üèÜSelected Awards</h2>
<ul>
	<li>
		<tr><td> Third Place, Shanghai-HK Interdisciplinary Shared Tasks Task 1 (2022) </td></tr>
	</li>
	<li>
		<tr><td> Third Price, The 13th Lanqiao Cup Algorithm Competition (2022) </td></tr>
	</li>
	<li>
		<tr><td> Second Price, The 3rd Huawei DIGIX AI Algorithm Contest (2021) </td></tr>
	</li>
	<li>
		<tr><td> Winning Prize, The 8th Newland Cup Computer Design Contest (2021) </td></tr>
	</li>
	<li>
		<tr><td> Honorable Mention, Mathematical Contest In Modeling (2021) </td></tr>
	</li>
	<li>
		<tr><td> Second Price, The 6th LSCAT Cup Translation Competition (2020) </td></tr>
	</li>
</ul>

<h2 id="education">üè´Education</h2>
<ul>
<li>	
	<tr><td> <b>Ph.D. in Electrical and Computer Systems</b> (Expected 2026) <br/>
	<div style="line-height:10px"><br/></div>
	Faculty of Engineering, <br>
	Monash University. <br>
	Advisor: A/Prof. <a href="https://scholar.google.com.au/citations?user=Q0gUrcIAAAAJ&hl=en">Zongyuan Ge</a>, Dr. <a href="https://research.monash.edu/en/persons/ben-duan">Peibo Duan</a> and Dr. <a href="https://scholar.google.com/citations?user=bbyetzcAAAAJ&hl=zh-CN&oi=ao">Deval Mehta</a>. <br>
	</td></tr>
</li>

<li>	
	<tr><td> <b>Bachelor of Engineering in Computer Science and Technology</b> (06/2023) <br/>
	<div style="line-height:10px"><br/></div>
	Artificial Intelligence Experimental Class, <br>
	School of Computer Science and Technology, <br>
	Soochow University. <br>
	<!-- Advisor: A/Prof. <a href="https://dblp.uni-trier.de/pid/08/500.html">Junhui Li</a> and A/Prof. <a href="https://lijuntaopku.github.io/">Juntao Li</a>. <br>	 -->
	</td></tr>
</li>
</ul>	

<div id="footer">
	<div id="footer-text"></div>
</div>
	<p> For Chinese version, please visit <a href="./cn_homepage.html" id="cn_name" style="font-family:STKaiti">‰∏≠ÊñáÁâà<a> </p>
	<p><center>
	<a href="https://info.flagcounter.com/0RkS"><img src="https://s05.flagcounter.com/map/0RkS/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>
      	<br> 
	&copy; Peng Xia | Last updated: May. 2023
		</center></p>


</div>

</body></html>
